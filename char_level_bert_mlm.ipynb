{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## module test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inputs: Encoding texts...: 100%|██████████| 2/2 [00:00<00:00, 17189.77it/s]\n",
      "Labels: Encoding texts...: 100%|██████████| 2/2 [00:00<00:00, 12690.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': tensor([[101, 316, 103, 315, 316, 102,   0],\n",
      "        [101, 304, 301, 308, 103, 311, 102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1]]), 'labels': tensor([[101, 316, 301, 315, 316, 102,   0],\n",
      "        [101, 304, 301, 308, 308, 311, 102]])}\n",
      "[CLS]t[MASK]st[SEP][PAD]\n",
      "[CLS]test[SEP][PAD]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from char_mlm import CharMLMDataset\n",
    "\n",
    "test = CharMLMDataset(\n",
    "    masked_texts=['t[MASK]st', 'hel[MASK]o'],\n",
    "    label_texts=['test', 'hello']\n",
    ")\n",
    "\n",
    "print(test.batch_encoding)\n",
    "print(test.tokenizer.decode(test[0]['input_ids']))\n",
    "print(test.tokenizer.decode(test[0]['labels']))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## loading dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inputs: Encoding texts...: 100%|██████████| 1249/1249 [00:00<00:00, 26260.26it/s]\n",
      "Labels: Encoding texts...: 100%|██████████| 1249/1249 [00:00<00:00, 27217.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total: 1249, train: 833, dev: 208, test: 208\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from char_mlm import CharMLMDataset\n",
    "from typing import List\n",
    "from torch.utils.data.dataset import random_split, Dataset, Subset\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "def random_split_by_ratio(\n",
    "    dataset: Dataset, ratio: List[int], *args, **kargs\n",
    ") -> List[Subset]:\n",
    "    dataset_length = len(dataset)\n",
    "    ratio_sum = sum(ratio)\n",
    "    lengths = [r * (dataset_length // ratio_sum) for r in ratio]\n",
    "    lengths[0] += dataset_length % ratio_sum\n",
    "    return random_split(dataset, lengths, *args, **kargs)\n",
    "\n",
    "\n",
    "def mask_idx(text: str, idx: int) -> str:\n",
    "   text = list(text)\n",
    "   text[idx] = '[MASK]'\n",
    "   return ''.join(text)\n",
    "\n",
    "\n",
    "sents_orgin = pd.read_csv('./Data/en_setence.csv').setence.to_list()[:10]\n",
    "sents, sents_masked = [], []\n",
    "\n",
    "for sent in sents_orgin:\n",
    "    for i in range(len(sent)):\n",
    "        sents.append(sent)\n",
    "        sents_masked.append(mask_idx(sent, i))\n",
    "\n",
    "sents_num = len(sents)\n",
    "sents\n",
    "\n",
    "data = CharMLMDataset(sents_masked, sents)\n",
    "\n",
    "train, dev, test = random_split_by_ratio(\n",
    "    data, [4, 1, 1]\n",
    ")\n",
    "print(f'total: {len(data)}, train: {len(train)}, dev: {len(dev)}, test: {len(test)}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trainer & Model definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import Trainer, BertForMaskedLM, BertConfig, TrainingArguments\n",
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0'\n",
    "\n",
    "MODEL_DIR = os.path.join(\n",
    "    './models', datetime.now().strftime(\"%Y-%m-%d-%H-%M-%S\")\n",
    ")\n",
    "\n",
    "model_config = BertConfig(\n",
    "    max_position_embeddings=1024,\n",
    ")\n",
    "model = BertForMaskedLM(model_config)\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=MODEL_DIR,\n",
    "    num_train_epochs=30,\n",
    "    evaluation_strategy='epoch',\n",
    "    logging_dir=os.path.join(MODEL_DIR, 'tensorboard'),\n",
    "    logging_strategy='epoch',\n",
    "    log_level='warning',\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model,\n",
    "    training_args,\n",
    "    train_dataset=train,\n",
    "    eval_dataset=dev,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3150' max='3150' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3150/3150 17:33, Epoch 30/30]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>4.309600</td>\n",
       "      <td>2.108867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.669700</td>\n",
       "      <td>0.042432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.020600</td>\n",
       "      <td>0.014642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.010800</td>\n",
       "      <td>0.012362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.007800</td>\n",
       "      <td>0.011815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.006000</td>\n",
       "      <td>0.010504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.005100</td>\n",
       "      <td>0.010579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.004400</td>\n",
       "      <td>0.010720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.003700</td>\n",
       "      <td>0.010809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.003200</td>\n",
       "      <td>0.011652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.002800</td>\n",
       "      <td>0.011272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.002500</td>\n",
       "      <td>0.011404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.002100</td>\n",
       "      <td>0.011791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.001900</td>\n",
       "      <td>0.012143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.001600</td>\n",
       "      <td>0.012564</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>0.001400</td>\n",
       "      <td>0.012403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>0.001400</td>\n",
       "      <td>0.012758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>0.012804</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>0.000900</td>\n",
       "      <td>0.013227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.000700</td>\n",
       "      <td>0.013155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21</td>\n",
       "      <td>0.000500</td>\n",
       "      <td>0.013664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>0.000500</td>\n",
       "      <td>0.014168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>0.014138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>0.014021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>0.014128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>0.014255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>0.014267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>0.014312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29</td>\n",
       "      <td>0.000200</td>\n",
       "      <td>0.014316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>0.000200</td>\n",
       "      <td>0.014299</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='26' max='26' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [26/26 00:02]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.014059482142329216, 'eval_runtime': 2.6785, 'eval_samples_per_second': 77.657, 'eval_steps_per_second': 9.707, 'epoch': 30.0}\n"
     ]
    }
   ],
   "source": [
    "trainer.train()\n",
    "trainer.save_model()\n",
    "test_result = trainer.evaluate(test)\n",
    "print(test_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "492feaf682b21470e654bff857dc2eb7fc8bb0ba6ce9addd9f7af7a048d541df"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit ('venv': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
